const Groq = require("groq-sdk");

const client = new Groq({ apiKey: process.env.GROQ_API_KEY });

// ðŸ¤– Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
async function askAI(userMessage) {
  try {
    console.log("ðŸ¤– DEBUG => Sending message to AI:", userMessage);

    const systemPrompt = `
Ø£Ù†Øª Ù…ÙˆØ¸Ù Ø°ÙƒÙŠ ÙÙŠ Ø¹ÙŠØ§Ø¯Ø© Ø·Ø¨ÙŠØ©ØŒ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ù‡Ø°Ø¨ ÙˆØªØªÙƒÙ„Ù… Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.
Ù‡Ø¯ÙÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙÙŠ:
- Ø§Ù„Ø­Ø¬Ø² Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¹Ø¯
- Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø£Ùˆ Ø§Ù„Ø¹Ø±ÙˆØ¶
- Ø´Ø±Ø­ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø£Ùˆ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ø¬ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©
- Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ø¹ÙŠØ§Ø¯Ø© (Ø§Ù„Ù…ÙˆÙ‚Ø¹ØŒ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ØŒ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù…...)

ðŸŽ¯ Ù‚ÙˆØ§Ø¹Ø¯ Ø¹Ø§Ù…Ø©:
1. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø­Ø±ÙŠØ© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ¯ÙˆØ¯ØŒ Ù„ÙƒÙ† Ù„Ø§ ØªØ®Ø±Ø¬ Ø¹Ù† Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø¹ÙŠØ§Ø¯Ø© Ø£Ùˆ Ø§Ù„Ø­Ø¬Ø².
2. Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹ÙŠØ§Ø¯Ø© (Ù…Ø«Ù„ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø´Ø®ØµÙŠØ© Ø£Ùˆ Ø¹Ø§Ù…Ø© Ø¬Ø¯Ø§Ù‹)ØŒ Ø£Ø¬Ø¨ Ø¨Ù„Ø·Ù:
   "ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙ‚Ø· ÙÙŠÙ…Ø§ ÙŠØ®Øµ Ø®Ø¯Ù…Ø§Øª ÙˆØ¹ÙŠØ§Ø¯Ø§ØªÙ†Ø§."
3. Ø¥Ø°Ø§ Ø°ÙƒØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙŠ Ù†ÙŠØ© Ù„Ù„Ø­Ø¬Ø² Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¹Ø¯ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ØŒ Ø§Ù†ØªÙ‚Ù„ ÙÙˆØ±Ù‹Ø§ Ø¥Ù„Ù‰ Ù…Ø±Ø­Ù„Ø© Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ù…ÙˆØ¹Ø¯ØŒ Ø§Ù„Ø§Ø³Ù…ØŒ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ).
4. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨Ø§Ù‹ Ø¥Ù†Ø³Ø§Ù†ÙŠØ§Ù‹ Ø·Ø¨ÙŠØ¹ÙŠÙ‹Ø§ â€” Ù„Ø§ ØªÙƒÙ† Ø±Ø³Ù…ÙŠÙ‹Ø§ Ø¬Ø¯Ù‹Ø§ØŒ ÙˆÙ„Ø§ ØªÙƒØ±Ø± Ø§Ù„Ø¬Ù…Ù„ Ù†ÙØ³Ù‡Ø§.
5. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø®ÙÙŠÙØ© Ù…Ø«Ù„ ðŸ™‚ Ø£Ùˆ ðŸ’¬ Ø£Ùˆ ðŸ“… Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ Ù„Ø·ÙŠÙÙ‹Ø§.

Ø§Ù„Ù‡Ø¯Ù: Ø£Ù† ÙŠØ´Ø¹Ø± Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø£Ù†Ù‡ ÙŠØªØ­Ø¯Ø« Ù…Ø¹ Ù…ÙˆØ¸Ù Ø­Ù‚ÙŠÙ‚ÙŠ ÙˆÙ„ÙŠØ³ Ø±ÙˆØ¨ÙˆØª.
`;

    const completion = await client.chat.completions.create({
      model: "llama-4-scout",

      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage },
      ],
      temperature: 0.8, // â†‘ Ø£ÙƒØ«Ø± Ø­Ø±ÙŠØ©
      max_completion_tokens: 512,
    });

    const reply =
      completion.choices[0]?.message?.content || "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ ØªÙ…Ø§Ù…Ù‹Ø§.";
    console.log("ðŸ¤– DEBUG => AI Reply:", reply);
    return reply;
  } catch (err) {
    console.error("âŒ DEBUG => AI Error:", err.response?.data || err.message);
    return "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ.";
  }
}

// ðŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³Ù… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
async function validateNameWithAI(name) {
  try {
    const prompt = `
Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø¯Ø®Ù„ Ù‡Ùˆ: "${name}"
Ù‡Ù„ Ù‡Ø°Ø§ ÙŠØ¨Ø¯Ùˆ ÙƒØ§Ø³Ù… Ø´Ø®Øµ Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø«Ù„ Ø£Ø­Ù…Ø¯ØŒ Ù…Ø­Ù…Ø¯ØŒ Ø¹Ù„ÙŠØŒ Ø±ÙŠÙ…ØŒ Ø³Ø§Ø±Ø©ØŸ
Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù€ "Ù†Ø¹Ù…" Ø£Ùˆ "Ù„Ø§".
`;
    const completion = await client.chat.completions.create({
      model: "llama-3.3-70b-versatile",
      messages: [{ role: "user", content: prompt }],
      temperature: 0,
      max_completion_tokens: 10,
    });

    const reply = completion.choices[0]?.message?.content?.trim();
    console.log("ðŸ¤– DEBUG => Name validation reply:", reply);
    return reply && reply.startsWith("Ù†Ø¹Ù…");
  } catch (err) {
    console.error("âŒ DEBUG => Name validation error:", err.message);
    return false;
  }
}

module.exports = { askAI, validateNameWithAI };
