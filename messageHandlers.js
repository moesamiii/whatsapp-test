/**
 * messageHandlers.js
 *
 * Purpose:
 * - Detect user intent from text/voice (location/offers/doctors).
 * - Provide message-sending flows that use media assets (location link, offer images, doctor images).
 * - Perform transcription of audio using Groq Whisper integration.
 *
 * Responsibilities kept here:
 * - Detection helpers: isLocationRequest, isOffersRequest, isDoctorsRequest, isEnglish
 * - sendLocationMessages: uses CLINIC_LOCATION_LINK from mediaAssets
 * - sendOffersImages & sendDoctorsImages: orchestrate sending multiple images and follow-up text
 * - sendImageMessage: performs the network request to WhatsApp API (requires WHATSAPP_TOKEN)
 * - transcribeAudio: fetches media from WhatsApp and posts to Groq Whisper
 *
 * Moved to mediaAssets.js:
 * - CLINIC_NAME
 * - CLINIC_LOCATION_LINK
 * - OFFER_IMAGES
 * - DOCTOR_IMAGES
 *
 * Usage:
 * - const { sendOffersImages, isLocationRequest, transcribeAudio } = require('./messageHandlers');
 */

const axios = require("axios");
const FormData = require("form-data");
const { sendTextMessage } = require("./helpers");

// Import static media assets from mediaAssets.js
const {
  CLINIC_NAME,
  CLINIC_LOCATION_LINK,
  OFFER_IMAGES,
  DOCTOR_IMAGES,
} = require("./mediaAssets");

// ---------------------------------------------
// Environment Variables
// ---------------------------------------------
const GROQ_API_KEY = process.env.GROQ_API_KEY;
const WHATSAPP_TOKEN = process.env.WHATSAPP_TOKEN;

// ---------------------------------------------
// ğŸ—ºï¸ Location Detection Helper
// ---------------------------------------------
function isLocationRequest(text = "") {
  const locationKeywords = [
    "Ù…ÙˆÙ‚Ø¹",
    "Ù…ÙƒØ§Ù†",
    "Ø¹Ù†ÙˆØ§Ù†",
    "ÙˆÙŠÙ†",
    "ÙÙŠÙ†",
    "Ø£ÙŠÙ†",
    "location",
    "where",
    "address",
    "place",
    "maps",
    "Ø§Ù„Ø¹ÙŠØ§Ø¯Ø©",
    "clinic",
    "ÙˆÙŠÙ†ÙƒÙ…",
    "ÙÙŠÙ†ÙƒÙ…",
  ];
  const lowerText = String(text).toLowerCase();
  return locationKeywords.some((keyword) => lowerText.includes(keyword));
}

// ---------------------------------------------
// ğŸ Offers & Services Detection Helper
// ---------------------------------------------
function isOffersRequest(text = "") {
  const offersKeywords = [
    "Ø¹Ø±ÙˆØ¶",
    "Ø®Ø¯Ù…Ø§Øª",
    "Ø£Ø³Ø¹Ø§Ø±",
    "Ø¹Ø±Ø¶",
    "Ø®Ø¯Ù…Ø©",
    "Ø³Ø¹Ø±",
    "offers",
    "services",
    "prices",
    "offer",
    "service",
    "price",
  ];
  const lowerText = String(text).toLowerCase();
  return offersKeywords.some((keyword) => lowerText.includes(keyword));
}

// ---------------------------------------------
// ğŸ‘¨â€âš•ï¸ Doctors Detection Helper
// ---------------------------------------------
function isDoctorsRequest(text = "") {
  const doctorsKeywords = [
    "Ø¯ÙƒØªÙˆØ±",
    "Ø¯ÙƒØ§ØªØ±Ø©",
    "Ø·Ø¨ÙŠØ¨",
    "Ø£Ø·Ø¨Ø§Ø¡",
    "Ø§Ù„Ø¯ÙƒØªÙˆØ±",
    "Ø§Ù„Ø·Ø¨ÙŠØ¨",
    "doctor",
    "doctors",
    "physician",
    "dr",
    "Ø§Ø·Ø¨Ø§Ø¡",
    "Ø§Ù„Ø§Ø·Ø¨Ø§Ø¡",
  ];
  const lowerText = String(text).toLowerCase();
  return doctorsKeywords.some((keyword) => lowerText.includes(keyword));
}

// ---------------------------------------------
// ğŸŒ Language Detection Helper
// ---------------------------------------------
function isEnglish(text = "") {
  const arabicPattern = /[\u0600-\u06FF]/;
  return !arabicPattern.test(String(text));
}

// ---------------------------------------------
// ğŸ“ Send Location Messages
// ---------------------------------------------
async function sendLocationMessages(to, language = "ar") {
  // First message: Just the link
  await sendTextMessage(to, CLINIC_LOCATION_LINK);

  // Small delay for better UX
  await new Promise((resolve) => setTimeout(resolve, 500));

  // Second message: Explanation
  if (language === "en") {
    await sendTextMessage(
      to,
      `ğŸ“ This is our location at ${CLINIC_NAME}. You can click on the link to open it in Google Maps ğŸ—ºï¸`
    );
  } else {
    await sendTextMessage(
      to,
      `ğŸ“ Ù‡Ø°Ø§ Ù‡Ùˆ Ù…ÙˆÙ‚Ø¹ ${CLINIC_NAME}. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„ÙØªØ­Ù‡ ÙÙŠ Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„ ğŸ—ºï¸`
    );
  }
}

// ---------------------------------------------
// ğŸ“¸ Send Image Helper (performs network call to WhatsApp)
// ---------------------------------------------
async function sendImageMessage(to, imageUrl) {
  try {
    await axios.post(
      `https://graph.facebook.com/v21.0/${process.env.PHONE_NUMBER_ID}/messages`,
      {
        messaging_product: "whatsapp",
        to: to,
        type: "image",
        image: {
          link: imageUrl,
        },
      },
      {
        headers: {
          Authorization: `Bearer ${WHATSAPP_TOKEN}`,
          "Content-Type": "application/json",
        },
      }
    );
  } catch (err) {
    console.error(
      "âŒ Failed to send image:",
      err.response?.data || err.message
    );
  }
}

// ---------------------------------------------
// ğŸ Send Offers & Services Images (uses OFFER_IMAGES from mediaAssets)
// ---------------------------------------------
async function sendOffersImages(to, language = "ar") {
  try {
    if (language === "en") {
      await sendTextMessage(to, "ğŸ’Š Here are our offers and services:");
    } else {
      await sendTextMessage(to, "ğŸ’Š Ù‡Ø°Ù‡ Ø¹Ø±ÙˆØ¶Ù†Ø§ ÙˆØ®Ø¯Ù…Ø§ØªÙ†Ø§ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:");
    }

    await new Promise((resolve) => setTimeout(resolve, 500));

    for (let i = 0; i < OFFER_IMAGES.length; i++) {
      await sendImageMessage(to, OFFER_IMAGES[i]);
      if (i < OFFER_IMAGES.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 800));
      }
    }

    await new Promise((resolve) => setTimeout(resolve, 500));
    if (language === "en") {
      await sendTextMessage(
        to,
        "âœ¨ For more details or to book an appointment, just let me know!"
      );
    } else {
      await sendTextMessage(
        to,
        "âœ¨ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø£Ùˆ Ù„Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯ØŒ Ø£Ø®Ø¨Ø±Ù†ÙŠ ÙÙ‚Ø·!"
      );
    }
  } catch (err) {
    console.error("âŒ Failed to send offers images:", err.message || err);
  }
}

// ---------------------------------------------
// ğŸ‘¨â€âš•ï¸ Send Doctors Images (uses DOCTOR_IMAGES from mediaAssets)
// ---------------------------------------------
async function sendDoctorsImages(to, language = "ar") {
  try {
    if (language === "en") {
      await sendTextMessage(to, "ğŸ‘¨â€âš•ï¸ Meet our professional medical team:");
    } else {
      await sendTextMessage(to, "ğŸ‘¨â€âš•ï¸ ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙØ±ÙŠÙ‚Ù†Ø§ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ù…ØªØ®ØµØµ:");
    }

    await new Promise((resolve) => setTimeout(resolve, 500));

    for (let i = 0; i < DOCTOR_IMAGES.length; i++) {
      await sendImageMessage(to, DOCTOR_IMAGES[i]);
      if (i < DOCTOR_IMAGES.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 800));
      }
    }

    await new Promise((resolve) => setTimeout(resolve, 500));
    if (language === "en") {
      await sendTextMessage(
        to,
        "âœ¨ Our experienced doctors are here to provide you with the best care! To book an appointment, just let us know ğŸ˜Š"
      );
    } else {
      await sendTextMessage(
        to,
        "âœ¨ Ø£Ø·Ø¨Ø§Ø¤Ù†Ø§ Ø°ÙˆÙˆ Ø§Ù„Ø®Ø¨Ø±Ø© Ù‡Ù†Ø§ Ù„ØªÙ‚Ø¯ÙŠÙ… Ø£ÙØ¶Ù„ Ø±Ø¹Ø§ÙŠØ© Ù„Ùƒ! Ù„Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯ØŒ ÙÙ‚Ø· Ø£Ø®Ø¨Ø±Ù†Ø§ ğŸ˜Š"
      );
    }
  } catch (err) {
    console.error("âŒ Failed to send doctors images:", err.message || err);
  }
}

// ---------------------------------------------
// ğŸ§  Voice Transcription Helper (using Groq Whisper)
// ---------------------------------------------
async function transcribeAudio(mediaId) {
  try {
    console.log("ğŸ™ï¸ Starting transcription for media ID:", mediaId);

    const mediaUrlResponse = await axios.get(
      `https://graph.facebook.com/v21.0/${mediaId}`,
      {
        headers: {
          Authorization: `Bearer ${WHATSAPP_TOKEN}`,
        },
      }
    );

    const mediaUrl = mediaUrlResponse.data.url;
    if (!mediaUrl) return null;

    const audioResponse = await axios.get(mediaUrl, {
      responseType: "arraybuffer",
      headers: {
        Authorization: `Bearer ${WHATSAPP_TOKEN}`,
      },
    });

    const form = new FormData();
    form.append("file", Buffer.from(audioResponse.data), {
      filename: "voice.ogg",
      contentType: "audio/ogg; codecs=opus",
    });
    form.append("model", "whisper-large-v3");
    form.append("language", "ar");
    form.append("response_format", "json");

    const result = await axios.post(
      "https://api.groq.com/openai/v1/audio/transcriptions",
      form,
      {
        headers: {
          Authorization: `Bearer ${GROQ_API_KEY}`,
          ...form.getHeaders(),
        },
      }
    );

    return result.data.text;
  } catch (err) {
    console.error(
      "âŒ Voice transcription failed:",
      err.response?.data || err.message
    );
    return null;
  }
}

// ---------------------------------------------
// Exports
// ---------------------------------------------
module.exports = {
  isLocationRequest,
  isOffersRequest,
  isDoctorsRequest,
  isEnglish,
  sendLocationMessages,
  sendOffersImages,
  sendDoctorsImages,
  sendImageMessage,
  transcribeAudio,
};
